{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import WikiCorpus, dictionary\n",
    "import gensim.downloader as api\n",
    "from compare_tools.configuration import wem_loader\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from htrc_features import utils\n",
    "from motes_corpus.youtube import YTCaptionCorpus\n",
    "from motes_corpus.subtitles import SubtitleCorpus\n",
    "from motes_corpus.hathibook import HathiCorpus\n",
    "from motes_corpus import modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning with the GloVe wiki gigaword 300 model, which as 40000 *uncased* tokens, trained on 6B tokens from Wikipedia in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wem_loader('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write vocab into a gensim dictionary format\n",
    "dict_path = '/data/motes/gigaword_300_dict.txt'\n",
    "if not os.path.exists(dict_path):\n",
    "    with open(dict_path, mode='w') as f:\n",
    "        f.write('1\\n')\n",
    "        for i, word in enumerate(model.vocab.keys()):\n",
    "            f.write('{}\\t{}\\t1\\n'.format(i, word))\n",
    "model_dict = dictionary.Dictionary.load_from_text(dict_path)\n",
    "n_words = len(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 'weiss')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words, model_dict[12345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Cooccurrence Matrix\n",
    "\n",
    "GloVe uses a weighting of $(w/w_{max})^\\alpha$ for words that occur less than $w_{max}$. In Pennington et al 2014, they use $w_{max}=100$ and $\\alpha=\\frac{3}{4}$. This will be done later - for now we're just collecting raw cooccurrence counts.\n",
    "\n",
    "\n",
    "- Good guide: http://www.foldl.me/2014/glove-python/\n",
    "\n",
    "### Baseline English Wikipedia\n",
    "\n",
    "This will be the foundation on which the children's corpus is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def only_every(gen, n):\n",
    "    ''' Only return every nth doc.'''\n",
    "    for i, page in gen:\n",
    "        if i % n == 0:\n",
    "            yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs processed: 0\t time: 11s\t docs/second: 0\n"
     ]
    }
   ],
   "source": [
    "wiki = WikiCorpus('/data/motes/enwiki/enwiki-latest-pages-articles.xml.bz2', lemmatize=False, dictionary=model_dict)\n",
    "wikicooc = modeling.train_coocurrence_matrix(wiki.get_texts(), model_dict,\n",
    "                                             window_size=10, print_every=5000)\n",
    "sparse.save_npz('/data/motes/enwiki_cooc_raw.npz', wikicooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats for partial matrix:\n",
    "- Full1: Docs processed: 317014   time: 68589s    docs/second: 4\n",
    "- Full 2: Docs processed: 31254    time: 4179s     docs/second: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348268"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "317014+31254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = WikiCorpus('/data/motes/simplewiki/simplewiki-latest-pages-articles.xml.bz2', lemmatize=False, dictionary=model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500, 14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000, 18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500, 23000, 23500, 24000, 24500, 25000, 25500, 26000, 26500, 27000, 27500, 28000, 28500, 29000, 29500, 30000, 30500, 31000, 31500, 32000, 32500, 33000, 33500, 34000, 34500, 35000, 35500, 36000, 36500, 37000, 37500, 38000, 38500, 39000, 39500, 40000, 40500, 41000, 41500, 42000, 42500, 43000, 43500, 44000, 44500, 45000, 45500, 46000, 46500, 47000, 47500, 48000, 48500, 49000, 49500, 50000, 50500, 51000, 51500, 52000, 52500, 53000, 53500, 54000, 54500, 55000, 55500, 56000, 56500, 57000, 57500, 58000, 58500, 59000, 59500, 60000, 60500, 61000, 61500, 62000, 62500, 63000, 63500, 64000, 64500, 65000, 65500, 66000, 66500, 67000, 67500, 68000, 68500, 69000, 69500, 70000, 70500, 71000, 71500, 72000, 72500, 73000, 73500, 74000, 74500, 75000, 75500, 76000, 76500, 77000, 77500, 78000, 78500, 79000, 79500, 80000, 80500, 81000, 81500, 82000, 82500, 83000, 83500, 84000, 84500, 85000, 85500, 86000, 86500, 87000, 87500, 88000, 88500, 89000, 89500, 90000, 90500, 91000, 91500, 92000, 92500, 93000, 93500, 94000, 94500, 95000, 95500, 96000, 96500, 97000, 97500, 98000, 98500, 99000, 99500, 100000, 100500, 101000, 101500, 102000, 102500, 103000, 103500, 104000, 104500, 105000, 105500, 106000, \n",
      " 27047022 106434\n"
     ]
    }
   ],
   "source": [
    "word_n = 0\n",
    "docs = 0\n",
    "for i, text in enumerate(wiki.get_texts()):\n",
    "    word_n += len(text)\n",
    "    docs += 1\n",
    "    if i % 50000 == 0:\n",
    "        print(i, end=', ')\n",
    "print('\\n', word_n, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikicooc = modeling.train_coocurrence_matrix(wiki.get_texts(), model_dict,\n",
    "                                             window_size=10, print_every=2000)\n",
    "sparse.save_npz('/data/motes/simplewiki_cooc_raw.npz', wikicooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': 9157014, 'docs': 15037, 'types': 265208}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_paths = glob.glob('/data/motes/yt_captions/**/*')\n",
    "ytcorpus = YTCaptionCorpus(caption_paths)\n",
    "ytcorpus.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs processed: 0\t time: 1s\t docs/second: 0\n",
      "Docs processed: 2000\t time: 85s\t docs/second: 23\n",
      "Docs processed: 4000\t time: 228s\t docs/second: 17\n",
      "Docs processed: 6000\t time: 340s\t docs/second: 17\n",
      "Docs processed: 8000\t time: 568s\t docs/second: 14\n",
      "Docs processed: 10000\t time: 802s\t docs/second: 12\n",
      "Docs processed: 12000\t time: 999s\t docs/second: 12\n",
      "Docs processed: 14000\t time: 1197s\t docs/second: 11\n"
     ]
    }
   ],
   "source": [
    "cooc = modeling.train_coocurrence_matrix(ytcorpus.tokens(), model_dict,\n",
    "                                         window_size=10, print_every=2000)\n",
    "sparse.save_npz('/data/motes/yt_cooc_raw_{}.npz'.format(time.strftime('%m-%d')), cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': 12436065, 'docs': 5737, 'types': 493642}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtitle_paths = glob.glob('/data/motes/show_subtitles/**/*')\n",
    "showcorpus = SubtitleCorpus(subtitle_paths)\n",
    "showcorpus.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs processed: 0\t time: 0s\t docs/second: 0\n",
      "Docs processed: 2000\t time: 708s\t docs/second: 2\n"
     ]
    }
   ],
   "source": [
    "cooc = modeling.train_coocurrence_matrix(showcorpus.tokens(), model_dict,\n",
    "                                         window_size=10, print_every=2000)\n",
    "sparse.save_npz('/data/motes/shows_cooc_raw_{}.npz'.format(time.strftime('%m-%d')), cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Children's Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/extracted-features-parquet-stubby/uc1/b88/uc1.b4088188.tokens.parquet'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidsbooks = pd.read_parquet('/data/motes/kids_books.parquet')\n",
    "book_paths = (['/data/extracted-features-parquet-stubby/{}.tokens.parquet'.format(utils.id_to_stubbytree(htid)) for htid in kidsbooks.htid])\n",
    "book_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'words': 5817930, 'docs': 22465, 'types': 104704}, 581793000.0, 2246500.0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate based on 1% of the corpus\n",
    "random.shuffle(book_paths)\n",
    "sample_prop = .01\n",
    "sample_size = int(len(book_paths) * sample_prop)\n",
    "htcorpus = HathiCorpus(book_paths[:sample_size])\n",
    "s = htcorpus.stats()\n",
    "s, s['words']/sample_prop, s['docs']/sample_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HathiTrust Children's books had to be processed in parallel because of size, using `scripts/ht_cooc_matrix.py`, so those need to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 28.6 s, total: 3min 58s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, lastdir in [('2005-10', '2005'), ('2000-05', '2000')]:\n",
    "    cooc = modeling.merge_sparse_matrices(glob.glob('/data/motes/ht_coocs/{}/*'.format(lastdir)))\n",
    "    sparse.save_npz('/data/motes/ht_coocs/ht_cooc_raw_{}'.format(name), cooc)\n",
    "\n",
    "# Combine all the decade matrices\n",
    "#cooc = modeling.merge_sparse_matrices(glob.glob('/data/motes/ht_coocs/ht_cooc_raw_1*'))\n",
    "#sparse.save_npz('/data/motes/ht_coocs/ht_cooc_raw_all', cooc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine matrixes with weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/motes/simplewiki_cooc_raw.npz \t 13086210.66666866\n",
      "/data/motes/yt_cooc_raw_09-07.npz \t 12011316.945634851\n",
      "/data/motes/shows_cooc_raw_09-07.npz \t 36357764.06587125\n",
      "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz \t 10457207.777608508\n",
      "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz \t 8335299.301917659\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz \t 113350320.77022566\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz \t 13482573.579135073\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz \t 14833244.88504179\n"
     ]
    }
   ],
   "source": [
    "# Get a sense of how big various matrixes are\n",
    "paths = glob.glob('/data/motes/*npz') + glob.glob('/data/motes/ht_coocs/ht_cooc_raw_[12]*')\n",
    "for path in paths:\n",
    "    print(path, '\\t', sparse.load_npz(path).tocsr()[:100,:100].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0100</th>\n",
       "      <th>0.0500</th>\n",
       "      <th>0.1000</th>\n",
       "      <th>0.2000</th>\n",
       "      <th>0.3000</th>\n",
       "      <th>0.4000</th>\n",
       "      <th>0.5000</th>\n",
       "      <th>0.6000</th>\n",
       "      <th>0.7000</th>\n",
       "      <th>0.8000</th>\n",
       "      <th>0.9000</th>\n",
       "      <th>0.9500</th>\n",
       "      <th>0.9600</th>\n",
       "      <th>0.9700</th>\n",
       "      <th>0.9800</th>\n",
       "      <th>0.9900</th>\n",
       "      <th>0.9970</th>\n",
       "      <th>0.9990</th>\n",
       "      <th>0.9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/data/motes/simplewiki_cooc_raw.npz</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.33</td>\n",
       "      <td>6.67</td>\n",
       "      <td>8.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>16.33</td>\n",
       "      <td>32.67</td>\n",
       "      <td>105.00</td>\n",
       "      <td>289.33</td>\n",
       "      <td>1982.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/yt_cooc_raw_09-07.npz</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.10</td>\n",
       "      <td>4.70</td>\n",
       "      <td>10.40</td>\n",
       "      <td>13.40</td>\n",
       "      <td>18.60</td>\n",
       "      <td>29.20</td>\n",
       "      <td>61.40</td>\n",
       "      <td>215.86</td>\n",
       "      <td>642.96</td>\n",
       "      <td>5401.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/shows_cooc_raw_09-07.npz</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.60</td>\n",
       "      <td>11.00</td>\n",
       "      <td>14.60</td>\n",
       "      <td>20.70</td>\n",
       "      <td>33.70</td>\n",
       "      <td>76.20</td>\n",
       "      <td>295.70</td>\n",
       "      <td>967.90</td>\n",
       "      <td>10097.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.49</td>\n",
       "      <td>6.08</td>\n",
       "      <td>20.18</td>\n",
       "      <td>212.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.43</td>\n",
       "      <td>5.77</td>\n",
       "      <td>19.13</td>\n",
       "      <td>200.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.34</td>\n",
       "      <td>14.97</td>\n",
       "      <td>54.28</td>\n",
       "      <td>643.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.67</td>\n",
       "      <td>6.90</td>\n",
       "      <td>23.47</td>\n",
       "      <td>253.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.65</td>\n",
       "      <td>6.84</td>\n",
       "      <td>23.13</td>\n",
       "      <td>249.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0.0100  0.0500  0.1000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               0.33    0.33    0.33   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 0.10    0.10    0.20   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              0.10    0.10    0.20   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      0.00    0.00    0.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      0.00    0.00    0.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    0.00    0.00    0.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      0.00    0.00    0.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    0.00    0.00    0.00   \n",
       "\n",
       "                                                0.2000  0.3000  0.4000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               0.33    0.67    0.67   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 0.40    0.50    0.70   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              0.30    0.50    0.60   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      0.01    0.01    0.01   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      0.01    0.01    0.01   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    0.01    0.01    0.01   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      0.00    0.01    0.01   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    0.01    0.01    0.01   \n",
       "\n",
       "                                                0.5000  0.6000  0.7000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               0.67    1.00    1.00   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 0.80    1.00    1.30   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              0.80    0.90    1.20   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      0.01    0.01    0.02   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      0.01    0.01    0.02   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    0.01    0.02    0.03   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      0.01    0.01    0.02   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    0.01    0.01    0.02   \n",
       "\n",
       "                                                0.8000  0.9000  0.9500  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               1.67    3.33    6.67   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 2.10    4.70   10.40   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              2.00    4.60   11.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      0.03    0.08    0.20   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      0.03    0.08    0.19   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    0.06    0.15    0.40   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      0.04    0.09    0.22   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    0.04    0.09    0.22   \n",
       "\n",
       "                                                0.9600  0.9700  0.9800  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               8.00   11.00   16.33   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                13.40   18.60   29.20   \n",
       "/data/motes/shows_cooc_raw_09-07.npz             14.60   20.70   33.70   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      0.27    0.38    0.64   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      0.26    0.37    0.61   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    0.54    0.79    1.36   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      0.29    0.42    0.71   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    0.29    0.42    0.70   \n",
       "\n",
       "                                                0.9900  0.9970  0.9990  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz              32.67  105.00  289.33   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                61.40  215.86  642.96   \n",
       "/data/motes/shows_cooc_raw_09-07.npz             76.20  295.70  967.90   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      1.49    6.08   20.18   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      1.43    5.77   19.13   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    3.34   14.97   54.28   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      1.67    6.90   23.47   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    1.65    6.84   23.13   \n",
       "\n",
       "                                                  0.9999  \n",
       "/data/motes/simplewiki_cooc_raw.npz              1982.03  \n",
       "/data/motes/yt_cooc_raw_09-07.npz                5401.40  \n",
       "/data/motes/shows_cooc_raw_09-07.npz            10097.11  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz      212.96  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz      200.72  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    643.40  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      253.57  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    249.92  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dists = []\n",
    "quantiles = [.01, .05, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95, .96, .97, .98, .99, .997, .999, .9999]\n",
    "for path in paths:\n",
    "    m = sparse.load_npz(path)\n",
    "    #m.data[m.data < 1] = 0\n",
    "    #m.eliminate_zeros()\n",
    "    a = np.quantile(m.data, quantiles)\n",
    "    del m\n",
    "    b = pd.Series(dict(zip(quantiles, a)))\n",
    "    b.name = path\n",
    "    all_dists.append(b)\n",
    "pd.DataFrame(all_dists).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distributions, if eliminating all cooccurrences below 1. As we see below, ther distributions end up being very similar for the Bag-of-words tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0100</th>\n",
       "      <th>0.0500</th>\n",
       "      <th>0.1000</th>\n",
       "      <th>0.2000</th>\n",
       "      <th>0.3000</th>\n",
       "      <th>0.4000</th>\n",
       "      <th>0.5000</th>\n",
       "      <th>0.6000</th>\n",
       "      <th>0.7000</th>\n",
       "      <th>0.8000</th>\n",
       "      <th>0.9000</th>\n",
       "      <th>0.9500</th>\n",
       "      <th>0.9900</th>\n",
       "      <th>0.9970</th>\n",
       "      <th>0.9990</th>\n",
       "      <th>0.9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/data/motes/simplewiki_cooc_raw.npz</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>7.00</td>\n",
       "      <td>13.67</td>\n",
       "      <td>67.67</td>\n",
       "      <td>210.00</td>\n",
       "      <td>554.67</td>\n",
       "      <td>3459.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/yt_cooc_raw_09-07.npz</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.00</td>\n",
       "      <td>13.23</td>\n",
       "      <td>28.80</td>\n",
       "      <td>158.70</td>\n",
       "      <td>535.39</td>\n",
       "      <td>1597.83</td>\n",
       "      <td>10706.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/shows_cooc_raw_09-07.npz</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>15.80</td>\n",
       "      <td>36.50</td>\n",
       "      <td>232.00</td>\n",
       "      <td>858.13</td>\n",
       "      <td>2688.03</td>\n",
       "      <td>26113.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.77</td>\n",
       "      <td>7.91</td>\n",
       "      <td>18.44</td>\n",
       "      <td>41.60</td>\n",
       "      <td>245.32</td>\n",
       "      <td>853.54</td>\n",
       "      <td>2527.43</td>\n",
       "      <td>22068.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.05</td>\n",
       "      <td>4.28</td>\n",
       "      <td>6.83</td>\n",
       "      <td>14.93</td>\n",
       "      <td>31.63</td>\n",
       "      <td>167.89</td>\n",
       "      <td>549.61</td>\n",
       "      <td>1591.98</td>\n",
       "      <td>10823.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.33</td>\n",
       "      <td>3.04</td>\n",
       "      <td>4.27</td>\n",
       "      <td>6.81</td>\n",
       "      <td>14.85</td>\n",
       "      <td>31.45</td>\n",
       "      <td>165.43</td>\n",
       "      <td>539.70</td>\n",
       "      <td>1540.72</td>\n",
       "      <td>11077.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0.0100  0.0500  0.1000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               1.00    1.00    1.00   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 1.00    1.00    1.00   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              1.00    1.00    1.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    1.01    1.07    1.15   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      1.01    1.07    1.14   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    1.01    1.07    1.14   \n",
       "\n",
       "                                                0.2000  0.3000  0.4000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               1.00    1.00    1.00   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 1.20    1.40    1.70   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              1.20    1.40    1.70   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    1.34    1.60    1.96   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      1.32    1.56    1.87   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    1.32    1.55    1.87   \n",
       "\n",
       "                                                0.5000  0.6000  0.7000  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               1.33    1.67    2.33   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 2.10    2.70    3.80   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              2.10    2.80    4.00   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    2.48    3.30    4.77   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      2.34    3.05    4.28   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    2.33    3.04    4.27   \n",
       "\n",
       "                                                0.8000  0.9000  0.9500  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz               3.33    7.00   13.67   \n",
       "/data/motes/yt_cooc_raw_09-07.npz                 6.00   13.23   28.80   \n",
       "/data/motes/shows_cooc_raw_09-07.npz              6.70   15.80   36.50   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz    7.91   18.44   41.60   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz      6.83   14.93   31.63   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz    6.81   14.85   31.45   \n",
       "\n",
       "                                                0.9900  0.9970   0.9990  \\\n",
       "/data/motes/simplewiki_cooc_raw.npz              67.67  210.00   554.67   \n",
       "/data/motes/yt_cooc_raw_09-07.npz               158.70  535.39  1597.83   \n",
       "/data/motes/shows_cooc_raw_09-07.npz            232.00  858.13  2688.03   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz  245.32  853.54  2527.43   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz    167.89  549.61  1591.98   \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz  165.43  539.70  1540.72   \n",
       "\n",
       "                                                  0.9999  \n",
       "/data/motes/simplewiki_cooc_raw.npz              3459.20  \n",
       "/data/motes/yt_cooc_raw_09-07.npz               10706.78  \n",
       "/data/motes/shows_cooc_raw_09-07.npz            26113.54  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz  22068.87  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz    10823.81  \n",
       "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz  11077.11  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dists = []\n",
    "quantiles = [.01,.05,.1,.2,.3,.4,.5,.6,.7,.8,.9,.95,.99, .997, .999, .9999]\n",
    "for path in paths:\n",
    "    m = sparse.load_npz(path)\n",
    "    m.data[m.data < 1] = 0\n",
    "    m.eliminate_zeros()\n",
    "    a = np.quantile(m.data, quantiles)\n",
    "    del m\n",
    "    b = pd.Series(dict(zip(quantiles, a)))\n",
    "    b.name = path\n",
    "    all_dists.append(b)\n",
    "pd.DataFrame(all_dists).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/motes/simplewiki_cooc_raw.npz\n",
      "/data/motes/yt_cooc_raw_09-07.npz\n",
      "/data/motes/shows_cooc_raw_09-07.npz\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz\n",
      "/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz\n",
      "/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz\n",
      "/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<400000x400000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 50926469 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_weights = [('/data/motes/simplewiki_cooc_raw.npz', 1.5, .34),\n",
    "                   ('/data/motes/yt_cooc_raw_09-07.npz', 2, .2),\n",
    "                   ('/data/motes/shows_cooc_raw_09-07.npz', 2, .2),\n",
    "                   ('/data/motes/ht_coocs/ht_cooc_raw_1850-1980.npz', .1, 1),\n",
    "                   ('/data/motes/ht_coocs/ht_cooc_raw_1980-90.npz', .2, 1),\n",
    "                   ('/data/motes/ht_coocs/ht_cooc_raw_1990-2000.npz', .3, 1),\n",
    "                   ('/data/motes/ht_coocs/ht_cooc_raw_2000-05.npz', .4, 1),\n",
    "                   ('/data/motes/ht_coocs/ht_cooc_raw_2005-10.npz', .5, 1)\n",
    "                  ]\n",
    "                   \n",
    "for i, (path, weight, drop_below) in enumerate(ordered_weights):\n",
    "    print(path)\n",
    "    partial_mat = sparse.load_npz(path)\n",
    "    if drop_below:\n",
    "        # Drop really low coocurrences\n",
    "        partial_mat.data[partial_mat.data < drop_below] = 0\n",
    "        partial_mat.eliminate_zeros()\n",
    "    if i == 0:\n",
    "        full_mat = partial_mat\n",
    "    else:\n",
    "        full_mat += partial_mat\n",
    "    # For stats - collect\n",
    "full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23077519.848555967 0.1 5016099596.501346\n",
      "/data/motes/coocs/shows_cooc_raw_09-07.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Combine with the OG EN Wiki\n",
    "# Load Sparse Matrix\n",
    "cooc = sparse.load_npz('/data/motes/coocs/enwiki_cooc_317k_raw.npz')\n",
    "print(cooc.data.max(), cooc.data.min(), cooc.data.sum())\n",
    "\n",
    "# Drop bottom 20% of (rare) coocs\n",
    "cutoff = np.quantile(cooc.data.data, .2)\n",
    "cooc.data[cooc.data < cutoff] = 0\n",
    "cooc.eliminate_zeros()\n",
    "\n",
    "margins = np.array(cooc.sum(0))[0]\n",
    "\n",
    "ordered_weights = [#('/data/motes/coocs/simplewiki_cooc_raw.npz', .5, .2),\n",
    "                   #('/data/motes/coocs/yt_cooc_raw_09-07.npz', .5, .2),\n",
    "                   ('/data/motes/coocs/shows_cooc_raw_09-07.npz', 1, .2),\n",
    "                   #('/data/motes/coocs/ht_coocs/ht_cooc_raw_1850-1980.npz', .1, 1),\n",
    "                   #('/data/motes/coocs/ht_coocs/ht_cooc_raw_1980-90.npz', .2, 1),\n",
    "                   #('/data/motes/coocs/ht_coocs/ht_cooc_raw_1990-2000.npz', .3, 1),\n",
    "                   #('/data/motes/coocs/ht_coocs/ht_cooc_raw_2000-05.npz', .4, 1),\n",
    "                   #('/data/motes/coocs/ht_coocs/ht_cooc_raw_2005-10.npz', .5, 1)\n",
    "                  ]\n",
    "\n",
    "for i, (path, weight, drop_below) in enumerate(ordered_weights):\n",
    "    print(path)\n",
    "    partial_mat = sparse.load_npz(path)\n",
    "    # Scale to same size as enwiki, then scale\n",
    "    size_diff = (margins[:200] / np.array(partial_mat.sum(0))[0][:200])\n",
    "    scaling = weight * size_diff[~np.isnan(size_diff)].mean()\n",
    "    if drop_below:\n",
    "        # Drop really low coocurrences\n",
    "        partial_mat.data[partial_mat.data < drop_below] = 0\n",
    "        partial_mat.eliminate_zeros()\n",
    "    cooc += (partial_mat * scaling)\n",
    "sparse.save_npz('/data/motes/coocs/shows_w_en.npz', cooc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0100        0.200000\n",
       "0.0500        0.400000\n",
       "0.1000        0.536830\n",
       "0.2000        0.666667\n",
       "0.3000        0.674892\n",
       "0.4000        0.900000\n",
       "0.5000        1.000000\n",
       "0.6000        1.333333\n",
       "0.7000        2.000000\n",
       "0.8000        3.249331\n",
       "0.9000        8.120466\n",
       "0.9500       19.700000\n",
       "0.9600       25.892300\n",
       "0.9700       36.499497\n",
       "0.9800       58.628357\n",
       "0.9900      128.877679\n",
       "0.9970      475.963757\n",
       "0.9990     1493.601192\n",
       "0.9999    14222.358332\n",
       "dtype: float64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.quantile(full_mat.data, quantiles)\n",
    "b = pd.Series(dict(zip(quantiles, a)))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncate\n",
    "\n",
    "If we were to truncate the vocabulary at $n$, what % of cooccurrences would be retained vs dropped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "percent_of_all_weight = []\n",
    "s = cooc.sum()\n",
    "m = cooc.tocsc()\n",
    "for i in range(0, 400000, 2000):\n",
    "    p = m[:i,:i].sum() / s\n",
    "    percent_of_all_weight.append(p)\n",
    "del m\n",
    "pd.Series(percent_of_all_weight, index=list(range(0, 100000, 2000))+list(range(100000, 450000, 50000))).iloc[10:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Python GloVe\n",
    " - this doesn't do fine-tuning, but that's fine for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277861985.5636423 0.4 56405196386.71731\n",
      "Performing 100 training epochs with 25 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n"
     ]
    }
   ],
   "source": [
    "n = 100000\n",
    "fpath = '/data/motes/coocs/all_weighted_3_model.npz'\n",
    "just_name = os.path.splitext(os.path.split(fpath)[-1])[0]\n",
    "\n",
    "cooc = sparse.load_npz(fpath)\n",
    "# Load Sparse Matrix\n",
    "print(cooc.data.max(), cooc.data.min(), cooc.data.sum())\n",
    "\n",
    "# Truncate just to top n words in vocab\n",
    "m = cooc.tocsc()[:n, :n].tocoo()\n",
    "glove = Glove(no_components=300, learning_rate=0.05) \n",
    "glove.fit(m, epochs=100, no_threads=25, verbose=True)\n",
    "del m\n",
    "dictionary = dict(list(model_dict.token2id.items())[:n])\n",
    "glove.add_dictionary(dictionary)\n",
    "\n",
    "# Convert to keyed vectors and save\n",
    "kv = modeling.glove_to_keyedvectors(glove)\n",
    "kv.save('/data/motes/models/{}_{}k.kv'.format(just_name, int(n/1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "kv.save('/data/motes/all_weighted_1_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10650"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100000\n",
    "word_sums = pd.Series(np.array(full_mat.sum(1))[:n, 0], index=glove.dictionary.keys())\n",
    "\n",
    "# only preserve vocab where there have been enough words seen\n",
    "with open('/data/motes/all_weighted_1_model_include_vocab.txt', mode='w') as f:\n",
    "    f.write('\\n'.join(word_sums[word_sums > 500].index.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
