{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtitle Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1: Collect Youtube Video ID list for Children's works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import motes_corpus.youtube as yt\n",
    "import youtube_transcript_api\n",
    "from pathlib import Path\n",
    "\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=312872897581-qii8av1f39ko8iavk4qp3sm8lqnp74op.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fyoutube.readonly&state=TqMKcUlLl6JGskvXpbJkLnnWFizLPS&prompt=consent&access_type=offline\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the authorization code:  4/4QGOuLG-pPT9fU3kKwOriGjAsAFUo5yLlKV5r5mAFlngB10RzNQFJx0\n"
     ]
    }
   ],
   "source": [
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "# Disable OAuthlib's HTTPS verification when running locally.\n",
    "\n",
    "os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "client_secrets_file = list(Path('..').glob('client_secret*'))[0]\n",
    "\n",
    "flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    client_secrets_file, scopes)\n",
    "\n",
    "credentials = flow.run_console()\n",
    "\n",
    "youtube_api = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Strategy 1 - Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the search API, search for common keywords for kids, and identify videos. These are then analyzed for `madeForKids` tags, and an analysis of titles generates for search keywords.\n",
    "\n",
    "https://developers.google.com/youtube/v3/docs/search/list\n",
    "\n",
    "Also, cycle through topicId, to ensure more results per query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicId = '/m/01k8wb' # Educational; see: https://developers.google.com/youtube/v3/docs/search/list\n",
    "#topicId = '/m/02jjt' # Entertainment \n",
    "#topicId = '/m/0f2f9' # TV-shows - a subset of education\n",
    "#topicId = None\n",
    "#topicId = '/m/0bzvm2' # Gaming\n",
    "#sortBy = 'rating' # date | rating | relevance | title | videoCount | viewCount\n",
    "# Queries ('relevance', in categories '/m/01k8wb', '/m/0f2f9', '/m/0bzvm2', with 'kids' appended to query):\n",
    "# To run: ['periwinkle', 'samurai', 'jr', 'mister', 'nickelodeon', 'gospel', 'maggie', 'meena', 'bears', 'gumball', 'hotline', 'jojo', 'kinder', 'songs', 'network', 'wash', 'clues', 'phonics', 'infantiles', 'uncle', 'yoga', 'toddlers', 'poems', 'бег', 'junior', 'pequeños', 'macdonald', 'episodes', 'seen', 'sight', 'bible']\n",
    "\n",
    "past_queries = ['pizza', 'christmas', 'firefighter', 'sticker', 'halloween', 'yummy', 'superhero',\n",
    "                \"children|kids|kid|teen|teens\",'superpowers', 'homework', 'easter', 'cupcake',\n",
    "                'mickey', 'upbeat', 'meatball', 'mario', 'hotdog', 'zombie', 'robotic', 'inator',\n",
    "                'astronaut', 'gadget','vroom', 'kidz', 'wheels', 'mountain', 'barbie', 'danger',\n",
    "                'cbc', 'xd', 'rangers','sesame street', 'paw patrol', 'playtime', 'cartoons']\n",
    "for q in ['cartoons']:\n",
    "    q = q + ' kids'\n",
    "    for topicId in ['/m/01k8wb', '/m/0f2f9', '/m/0bzvm2', '/m/0f2f9','/m/0403l3g', '/m/025zzc', '/m/019_rr', '/m/02vxn', '/m/01k8wb', '/m/02jjt', '/m/09kqc', None, '/m/03glg', '/m/0bzvm2']:\n",
    "        for sortBy in ['relevance']: #['date', 'relevance', 'viewCount', 'rating']:\n",
    "            print(q, topicId, sortBy)\n",
    "            pt = None\n",
    "            results_collector = []\n",
    "\n",
    "            for i in range(40):\n",
    "                pt, df = yt.search_youtube(youtube_api, q, pageToken=pt, topicId=topicId, order=sortBy)\n",
    "                print(i, 'Next pageToken:', pt)\n",
    "                results_collector.append(df)\n",
    "                if (pt is None) or (df.shape[0] == 0):\n",
    "                    break\n",
    "\n",
    "            all_searches = pd.concat(results_collector)\n",
    "            if all_searches.empty:\n",
    "                continue\n",
    "            all_searches['q'] = q\n",
    "            all_searches['topicId'] = topicId\n",
    "            all_searches['sortBy'] = sortBy\n",
    "            now = int(time.time())\n",
    "            all_searches.to_parquet('data/yt_info/initial_search_results_{}.parquet'.format(now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection Strategy 2 - Downloading all videos for relevant channels\n",
    "\n",
    "Calling the channels call gives you an 'uploads' playlist, which can be used to download all the videos of that channel. Quota costs are much lower in that case.\n",
    "\n",
    "This does analysis on the 'details' dataframes, which are collected below, so if you have not data callected your, this section won't run yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine channels with madeForKids content and download details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>channelId</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Phineas and Ferb</td>\n",
       "      <td>UCsbTCrt-Ndfa2DfR5NJn5fg</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>NickJrPlay</td>\n",
       "      <td>UCkR8cM4gLPE7iV49cOitR3Q</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Mickey Mouse Clubhouse</td>\n",
       "      <td>UC8bcK-NGFJbOfGrXX5Y_VIQ</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Sesame Street</td>\n",
       "      <td>UCEn8ua5KNErvgsHADUWIVWQ</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Henry Danger</td>\n",
       "      <td>UCgVQOLcpiphDMySH8CTm5WQ</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>JESSIE</td>\n",
       "      <td>UCtLOBSdu37g_iLYMTW1vn7g</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Caillou</td>\n",
       "      <td>UCnPBcrNgQXXjE1SUGH2AtVA</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>Team Umizoomi</td>\n",
       "      <td>UCLLyHMqMLCt8cu6SsmMiQMw</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>The Jetsons</td>\n",
       "      <td>UCNRep6MD5OE2li7wfLpi-MQ</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Family And Kids Games</td>\n",
       "      <td>UC4TSKUgUvVvec5o-3Fzkb7Q</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                channelTitle                 channelId  count\n",
       "897         Phineas and Ferb  UCsbTCrt-Ndfa2DfR5NJn5fg     30\n",
       "823               NickJrPlay  UCkR8cM4gLPE7iV49cOitR3Q     30\n",
       "753   Mickey Mouse Clubhouse  UC8bcK-NGFJbOfGrXX5Y_VIQ     29\n",
       "1009           Sesame Street  UCEn8ua5KNErvgsHADUWIVWQ     15\n",
       "490             Henry Danger  UCgVQOLcpiphDMySH8CTm5WQ     11\n",
       "539                   JESSIE  UCtLOBSdu37g_iLYMTW1vn7g     11\n",
       "173                  Caillou  UCnPBcrNgQXXjE1SUGH2AtVA     10\n",
       "1108           Team Umizoomi  UCLLyHMqMLCt8cu6SsmMiQMw      9\n",
       "1139             The Jetsons  UCNRep6MD5OE2li7wfLpi-MQ      8\n",
       "373    Family And Kids Games  UC4TSKUgUvVvec5o-3Fzkb7Q      8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_parquet('data/yt_info/details*').drop_duplicates('videoId')\n",
    "ddf = ddf[ddf.madeForKids == True]\n",
    "top_channels = ddf.groupby(['channelTitle', 'channelId'])[['videoId']].count().compute()\n",
    "top_channels = top_channels.reset_index().sort_values('videoId', ascending=False).rename(columns={'videoId':'count'})\n",
    "\n",
    "channelinfo = dd.read_parquet('data/yt_info/channelInfo*')\n",
    "if len(channelinfo) > 0:\n",
    "    already_processed_channels = channelinfo.channelId.compute().tolist()\n",
    "else:\n",
    "    already_processed_channels = []\n",
    "\n",
    "top_channels = top_channels[~top_channels.channelId.isin(already_processed_channels)]\n",
    "top_channels = top_channels[top_channels['count'] > 1]\n",
    "top_channels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,(35, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>customUrl</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>madeForKids</th>\n",
       "      <th>uploads</th>\n",
       "      <th>favorites</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UC01n7Sn93HVMIi3HKZNxrTA</td>\n",
       "      <td>Hampton Primary School</td>\n",
       "      <td>Hampton School, Mauritius. Helpful videos for ...</td>\n",
       "      <td>hamptonprimaryschoolquatrebornes</td>\n",
       "      <td>2012-10-31T17:22:02Z</td>\n",
       "      <td>True</td>\n",
       "      <td>UU01n7Sn93HVMIi3HKZNxrTA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   channelId                   title  \\\n",
       "13  UC01n7Sn93HVMIi3HKZNxrTA  Hampton Primary School   \n",
       "\n",
       "                                          description  \\\n",
       "13  Hampton School, Mauritius. Helpful videos for ...   \n",
       "\n",
       "                           customUrl           publishedAt madeForKids  \\\n",
       "13  hamptonprimaryschoolquatrebornes  2012-10-31T17:22:02Z        True   \n",
       "\n",
       "                     uploads favorites likes  \n",
       "13  UU01n7Sn93HVMIi3HKZNxrTA                  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_info = yt.load_channel_info(youtube_api, top_channels.channelId)\n",
    "channel_info.to_parquet('data/yt_info/channelInfo_{}.parquet'.format(time.strftime('%m-%d')))\n",
    "print(channel_info.shape)\n",
    "channel_info.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `uploads` field is a special playlist that links to all the uploads for the channel. `favorites` and `likes` may be slightly useful.\n",
    "\n",
    "Channels can be `True`, `False`, or `NaN` for madeForKids. `True` is the sensible focus, though `NaN` may be useful too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 UUe1VpF4wS_kdcjyTRSXBcnQ\n",
      "138 videos found\n",
      "1 UUpgxmlXoDtkYzRQ4cJgCT5A\n",
      "2698 videos found\n",
      "2 UUUe6ZpY6TJ0no8jI4l2iLxw\n",
      "3625 videos found\n",
      "3 UU3KknIJZXRygH2pZ6MDtGbg\n",
      "2218 videos found\n",
      "4 UUaKkjxZBucoNihPw1NOqThA\n",
      "322 videos found\n",
      "5 UUcIVSA2vFpZmuPXG1oAZVaQ\n",
      "652 videos found\n",
      "6 UUwC-DciMGGk9AgpJ3hpreHw\n",
      "201 videos found\n",
      "7 UUABKyuM59C8Z0iDf-3kIRSA\n",
      "1035 videos found\n",
      "8 UURFIPG2u1DxKLNuE3y2SjHA\n",
      "379 videos found\n",
      "9 UUx27Pkk8plpiosF14qXq-VA\n",
      "546 videos found\n",
      "10 UUkbi6oVP_8Yzk9qPDfz9etw\n",
      "105 videos found\n",
      "11 UUcbE7twlpJfQVF2dO21fB1A\n",
      "2044 videos found\n",
      "12 UUcJT_hEkkQ03NAzp_6NEBiw\n",
      "2249 videos found\n",
      "13 UUQnSQLzMbkSN5j0rtYyPnmQ\n",
      "535 videos found\n",
      "14 UUAy25gXkma1g7_kaxupFqWg\n",
      "161 videos found\n",
      "15 UUV1SycDpnU1A2dXqob6Aowg\n",
      "135 videos found\n",
      "16 UU5M_h2S8Ldoc9M6f7B-_m6A\n",
      "3259 videos found\n",
      "17 UU-4za12KjAMe1RIHeL3grAw\n",
      "174 videos found\n",
      "18 UUdtojT_ZwTRlZThoBSMVhoQ\n",
      "558 videos found\n",
      "19 UU_6TpaXzCHZBTEs7oHLPXYA\n",
      "752 videos found\n",
      "20 UUoookXUzPciGrEZEXmh4Jjg\n",
      "3056 videos found\n",
      "21 UUm9SlTdSngChZypOUVcRYNQ\n",
      "516 videos found\n",
      "22 UU3Gv4u2_q5wQoonn5cqyadg\n",
      "2208 videos found\n",
      "23 UUgMV66LqpfH8CJJK7SL05Vw\n",
      "204 videos found\n",
      "24 UUGwA4GjY4nGMIYvaJiA0EGA\n",
      "928 videos found\n",
      "25 UUlPzMXh4d5baHqR_tSeiagw\n",
      "269 videos found\n",
      "26 UUN8S4CqMRy6tVKVXvs7Bzeg\n",
      "4811 videos found\n",
      "27 UUv2LP7wLfNaiE2Bo5klABeQ\n",
      "152 videos found\n",
      "28 UUWM0eBfdOLgW2l10I8HA0hw\n",
      "229 videos found\n",
      "29 UU8NFs-VWUsyuq4zaYVVMgCQ\n",
      "138 videos found\n",
      "30 UUBuMwlP7kHkNxdPAqtFSJTw\n",
      "80 videos found\n",
      "31 UUm3hAp1m1xlAz0ve_EKAo4g\n",
      "288 videos found\n",
      "32 UUY26xU0-avwTJ6F6TzUZVEw\n",
      "3959 videos found\n",
      "33 UUbH4Ii9Htdqc-QgxoV3M0Qw\n",
      "168 videos found\n",
      "34 UUVcQH8A634mauPrGbWs7QlQ\n",
      "1096 videos found\n",
      "35 UUNcdbMyA59zE-Vk668bKWOg\n",
      "2315 videos found\n",
      "36 UUFeUyPY6W8qX8w2o6oSiRmw\n",
      "513 videos found\n",
      "37 UU6XTIVq86zJPKNeiPay1czQ\n",
      "374 videos found\n",
      "38 UUTsgmnXbWotzbR36vU0YPrA\n",
      "423 videos found\n",
      "39 UUFKrbHKFDXN2xeDYKPQ5UiQ\n",
      "781 videos found\n",
      "40 UUWCOoCApFUtccYENOYeL1uw\n",
      "2484 videos found\n",
      "41 UUJykHJfN9FHtf79IgYE00zg\n",
      "352 videos found\n",
      "42 UUHeiD__PeWyxKVh9cm4s2IQ\n",
      "187 videos found\n",
      "43 UUO1BdQ04EHFh2XOzNycKZAQ\n",
      "1588 videos found\n",
      "44 UUBsITBarfoIQfCq8lxvETTQ\n",
      "67 videos found\n",
      "45 UUOOVKsLIVXnqCVfpu7xlPmQ\n",
      "28 videos found\n",
      "46 UUbg1xn1JhBqKpL2M6xi5-0A\n",
      "444 videos found\n",
      "47 UUZOdDXmNudkpLwhtjUyZJFQ\n",
      "1437 videos found\n",
      "48 UUjZo1E1P6wDDyw6ImVgKM-A\n",
      "215 videos found\n",
      "49 UU-qWJlvaPME3MWvrY-yjXeA\n",
      "76 videos found\n",
      "50 UU4L7VhfYiR9CWjlbJgQx7FA\n",
      "122 videos found\n",
      "51 UUwl5RE0vM0sBVQzRvM965fw\n",
      "279 videos found\n",
      "52 UUebMFnw6WxozGmqGekJHOJg\n",
      "264 videos found\n",
      "53 UU3A6xI-hi79MEQIo-yVX4uA\n",
      "65 videos found\n",
      "54 UU7Pq3Ko42YpkCB_Q4E981jw\n",
      "2832 videos found\n",
      "55 UUAJnyTWJPpKXuwgWQDdNWrQ\n",
      "889 videos found\n",
      "56 UUDCNmuaOXOo25Yn4mbMHhhQ\n",
      "349 videos found\n",
      "57 UUuBGpIc3UtmWiqFJ8ZyAf1A\n",
      "1074 videos found\n",
      "58 UUzEIEA6JW0VtCnYdu2uJEiQ\n",
      "368 videos found\n",
      "59 UUan48A3vtMqg1gvYmHl-iVA\n",
      "210 videos found\n",
      "60 UUl2boPpb2X5tjJ21rhtWrIA\n",
      "698 videos found\n",
      "61 UUNbbreT8es657nkCR7xVfcg\n",
      "31 videos found\n",
      "62 UUwynFfAvCF2kiRSMWiozQHg\n",
      "636 videos found\n",
      "63 UU6LKuH7RPkvRmzS9-8URtqA\n",
      "525 videos found\n",
      "64 UUnRuuiSVqDF2EmoYS7yE6ZA\n",
      "872 videos found\n",
      "65 UUYSQsLQx-R7DvYCUVL9GMyA\n",
      "429 videos found\n",
      "66 UUwJncBmXoz4njCjrfvI9bng\n"
     ]
    }
   ],
   "source": [
    "all_channel_info = dd.read_parquet('data/yt_info/channelInfo*')\n",
    "all_channel_info = all_channel_info[all_channel_info.madeForKids == True]\n",
    "processed = dd.read_parquet('data/yt_info/channel_details*').channelId.compute()\n",
    "processed += ['UCwJncBmXoz4njCjrfvI9bng'] # Exclude list for inappropriately tagged channels, like the Kentucky news station with 17k vids.\n",
    "all_channel_info = all_channel_info[~all_channel_info.channelId.isin(processed)]\n",
    "all_channel_info = all_channel_info.compute()\n",
    "\n",
    "collector = []\n",
    "for i, playlistID in enumerate(all_channel_info.uploads):\n",
    "    print(i, playlistID)\n",
    "    details = yt.playlist_details(youtube_api, playlistID)\n",
    "    print(\"{} videos found\".format(len(details)))\n",
    "    collector.append(details)\n",
    "df = pd.concat(collector)\n",
    "# Unfortunately, playlistItems didn't give us 'caption' info, so need to \n",
    "# ping the API one more time\n",
    "df2 = yt.augment_initial_search(youtube_api, df)\n",
    "df2.to_parquet('data/yt_info/channel_details_{}.parquet'.format(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Details\n",
    "\n",
    "Particularly important is whether the video is 'madeForKids'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting data/yt_info/initial_search_results_1602364309.parquet-->data/yt_info/details_search_results_1602364309.parquet\n",
      "0,1,2,3,4,5,6,7,8,9,10,\n",
      "Augmenting data/yt_info/initial_search_results_1602364314.parquet-->data/yt_info/details_search_results_1602364314.parquet\n",
      "0,1,2,3,4,5,6,7,8,\n",
      "Augmenting data/yt_info/initial_search_results_1602364320.parquet-->data/yt_info/details_search_results_1602364320.parquet\n",
      "0,1,2,3,4,5,6,7,8,9,10,\n",
      "Augmenting data/yt_info/initial_search_results_1602364325.parquet-->data/yt_info/details_search_results_1602364325.parquet\n",
      "0,1,2,3,4,5,6,7,8,9,10,\n",
      "Augmenting data/yt_info/initial_search_results_1602364330.parquet-->data/yt_info/details_search_results_1602364330.parquet\n",
      "0,1,2,3,4,5,6,7,8,9,\n",
      "Augmenting data/yt_info/initial_search_results_1602364333.parquet-->data/yt_info/details_search_results_1602364333.parquet\n",
      "0,1,2,3,4,5,6,7,\n"
     ]
    }
   ],
   "source": [
    "# Find the first file of *initial* search results that hasn't been queried for\n",
    "# extra info yet.\n",
    "data_paths = glob.glob('data/yt_info/*')\n",
    "for initial_path in [x for x in data_paths if 'initial' in x]:\n",
    "    details_path = initial_path.replace('initial', 'details')\n",
    "    if details_path in data_paths:\n",
    "        continue\n",
    "    else:\n",
    "        print('Augmenting {}-->{}'.format(initial_path, details_path))\n",
    "        df = pd.read_parquet(initial_path).drop_duplicates('videoId')\n",
    "        df2 = yt.augment_initial_search(youtube_api, df)\n",
    "        df2.to_parquet(details_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate common words in made for kids titles vs others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top topics ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv('yt_topic_ids.tsv', sep='\\t', names=['topic_id', 'name'])\n",
    "topicid2name = topics.set_index('topic_id').to_dict()['name']\n",
    "topicname2id = topics.set_index('name').to_dict()['topic_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('yt_topic_ids.tsv', sep='\\t', names=['topic_id', 'name']).set_index('topic_id').iloc[0].to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      /m/04rlf\n",
       "1     /m/02mscn\n",
       "2     /m/0ggq0m\n",
       "3      /m/01lyv\n",
       "4      /m/02lkt\n",
       "        ...    \n",
       "57     /m/0kt51\n",
       "58    /m/01h6rj\n",
       "59     /m/05qt0\n",
       "60     /m/06bvp\n",
       "61    /m/01k8wb\n",
       "Name: topic_id, Length: 62, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics['topic_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entertainment (parent topic)    2934\n",
       "Movies                          2394\n",
       "TV shows                        2365\n",
       "Knowledge                       1798\n",
       "Gaming (parent topic)           1468\n",
       "Action game                      248\n",
       "Music (parent topic)             219\n",
       "Role-playing video game          173\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top topic ids. obviously skewed to the ones searched for!\n",
    "df = dd.read_parquet(glob.glob('data/yt_info/details_*')).drop_duplicates(['videoId']).compute()\n",
    "past_searches= [] #['/m/0f2f9', '/m/0403l3g', '/m/019_rr', '/m/02vxn', '/m/01k8wb', '/m/02jjt', '/m/09kqc', None, '/m/03glg', '/m/0bzvm2']\n",
    "kids = df[df.madeForKids > 0]\n",
    "top_topics = pd.Series([x for y in kids.relevantTopicIds.dropna().tolist() for x in y if (x not in past_searches)]).value_counts()\n",
    "top_topics = top_topics[top_topics.index.isin(topics['topic_id'])]\n",
    "top_topics.index = [topicid2name[x] for x in top_topics.index]\n",
    "top_topics.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top words used in kids titles vs non-madeForKids titles?\n",
    "\n",
    "Using odds-ratio here, without a correction for missing words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchDetails = dd.read_parquet('data/yt_info/details*')\n",
    "channelDetails = dd.read_parquet('data/yt_info/channel_details*')\n",
    "intersect = list(set(searchDetails.columns).intersection(channelDetails.columns))\n",
    "blacklist = ['UCwJncBmXoz4njCjrfvI9bng']\n",
    "ddf = dd.concat([searchDetails[intersect], channelDetails[intersect]])\n",
    "ddf = ddf[~ddf.channelId.isin(blacklist)]\n",
    "df = ddf.drop_duplicates('videoId').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "kids_titles = \" \".join(df[df.madeForKids > 0].title.tolist())\n",
    "adult_titles = \" \".join(df[df.madeForKids == 0].title.tolist())\n",
    "\n",
    "kids_words = pd.Series(kids_titles.lower().split()).value_counts()\n",
    "adult_words = pd.Series(adult_titles.lower().split()).value_counts()\n",
    "\n",
    "kids_words = kids_words[kids_words > 1]\n",
    "adult_words = adult_words[adult_words > 1]\n",
    "\n",
    "kprob = kids_words / kids_words.sum()\n",
    "aprob = adult_words / adult_words.sum()\n",
    "kodds = kprob / (1-kprob)\n",
    "aodds = aprob / (1-aprob)\n",
    "odds_ratio = (kodds/aodds).dropna().apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cbc', 'xd', 'uk', 'rangers', 'sesame', 'paw', 'loud', 'motu', 'compilation', 'patlu', 'charge', 'pals', 'nick', 'hoffman', 'shine', 'playtime', 'abby', 'cartoons', 'periwinkle', 'samurai', 'jr', 'mister', 'nickelodeon', 'gospel', 'maggie', 'meena', 'bears', 'gumball', 'hotline', 'jojo', 'kinder', 'songs', 'network', 'wash', 'clues', 'phonics', 'infantiles', 'uncle', 'yoga', 'toddlers', 'poems', 'бег', 'junior', 'patrol', 'pequeños', 'macdonald', 'episodes', 'seen', 'sight', 'bible']\n"
     ]
    }
   ],
   "source": [
    "print(odds_ratio[odds_ratio.index.str.isalpha() & ~odds_ratio.index.isin(past_queries)].sort_values(ascending=False).index.tolist()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cbc            4.857021\n",
       "xd             4.177063\n",
       "uk             3.840047\n",
       "rangers        3.589981\n",
       "sesame         3.531126\n",
       "paw            3.500636\n",
       "loud           3.451253\n",
       "motu           3.348485\n",
       "compilation    3.318697\n",
       "patlu          3.288349\n",
       "charge         3.150285\n",
       "pals           3.121334\n",
       "nick           3.095340\n",
       "hoffman        3.035694\n",
       "shine          3.026230\n",
       "playtime       3.008160\n",
       "abby           3.002937\n",
       "cartoons       2.992741\n",
       "periwinkle     2.991513\n",
       "samurai        2.988994\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_ratio[odds_ratio.index.str.isalpha() & ~odds_ratio.index.isin(past_queries)].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which channels are best represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PBS KIDS                              2190\n",
       "HiHiPuffyAmiYumiRules2001              601\n",
       "ZZ Kids TV                             179\n",
       "Math Department                        120\n",
       "SAIL TAHITI                             97\n",
       "Parkfield Primary                       94\n",
       "Funny Shark for Kids                    93\n",
       "Nivu's World                            79\n",
       "Cross Church                            57\n",
       "Heidi and Toys                          53\n",
       "Hemet Unified                           50\n",
       "kitki                                   47\n",
       "Nickelodeon                             35\n",
       "Paw Pack - Funny Cartoons for Kids      33\n",
       "A Kid Explains History                  32\n",
       "Wolfoo Family                           28\n",
       "YouTube Movies                          25\n",
       "Guddies by Aditi Neel                   24\n",
       "TuRuLaRa- Gags For Kids                 23\n",
       "GamerGirl                               18\n",
       "Name: channelTitle, dtype: int64"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.madeForKids > 0].channelTitle.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which search condition has the best hit rate for 'madeForKids' content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>madeForKids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topicId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/m/02vxn</th>\n",
       "      <td>0.905797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02jjt</th>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01k8wb</th>\n",
       "      <td>0.570934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/03glg</th>\n",
       "      <td>0.514423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/02jjt</th>\n",
       "      <td>0.450704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0f2f9</th>\n",
       "      <td>0.440678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/01k8wb</th>\n",
       "      <td>0.411894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/09kqc</th>\n",
       "      <td>0.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/019_rr</th>\n",
       "      <td>0.286932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0bzvm2</th>\n",
       "      <td>0.270415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/m/0403l3g</th>\n",
       "      <td>0.056872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            madeForKids\n",
       "topicId                \n",
       "/m/02vxn       0.905797\n",
       "02jjt          0.611111\n",
       "01k8wb         0.570934\n",
       "/m/03glg       0.514423\n",
       "/m/02jjt       0.450704\n",
       "/m/0f2f9       0.440678\n",
       "/m/01k8wb      0.411894\n",
       "/m/09kqc       0.373626\n",
       "/m/019_rr      0.286932\n",
       "/m/0bzvm2      0.270415\n",
       "/m/0403l3g     0.056872"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['topicId'])[['madeForKids']].apply(lambda x: x.sum()/x.count()).sort_values('madeForKids', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['sortBy'])[['madeForKids']].apply(lambda x: x.sum()/x.count()).sort_values('madeForKids', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2: Download Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed = [os.path.split(x)[1][:-5] for x in glob.glob('/data/motes/yt_captions/**/*') if x.endswith('.json')]\n",
    "with open('completed.txt', mode='w') as f:\n",
    "    f.write(\"\\n\".join(completed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49219 42221\n",
      "10558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>caption</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>relevantTopicIds</th>\n",
       "      <th>description</th>\n",
       "      <th>topicCategories</th>\n",
       "      <th>videoId</th>\n",
       "      <th>channelId</th>\n",
       "      <th>duration</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>title</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>madeForKids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>YouTube Movies</td>\n",
       "      <td>[/m/02jjt, /m/02vxn, /m/02jjt, /m/02vxn, /m/0f...</td>\n",
       "      <td>Arthur, D.W., and their family and friends pre...</td>\n",
       "      <td>[https://en.wikipedia.org/wiki/Film, https://e...</td>\n",
       "      <td>YBa8fm5w1WQ</td>\n",
       "      <td>UC6Qs46AHswdgMq08dqaQbQQ</td>\n",
       "      <td>PT54M35S</td>\n",
       "      <td>2015-11-02T14:10:57Z</td>\n",
       "      <td>Arthur&amp;#39;s Perfect Christmas</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>None</td>\n",
       "      <td>true</td>\n",
       "      <td>Top Elf</td>\n",
       "      <td>[/m/02jjt, /m/0f2f9, /m/02jjt, /m/0f2f9, /m/0f...</td>\n",
       "      <td>5 talented Elf-testants are in the running for...</td>\n",
       "      <td>[https://en.wikipedia.org/wiki/Entertainment, ...</td>\n",
       "      <td>1vHTAHEeTco</td>\n",
       "      <td>UCJhhiv2zac33YdOC2He3uLg</td>\n",
       "      <td>PT43M5S</td>\n",
       "      <td>2019-12-14T05:00:01Z</td>\n",
       "      <td>Teamwork Makes the Tree Work</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tags caption    channelTitle  \\\n",
       "58  None    true  YouTube Movies   \n",
       "68  None    true         Top Elf   \n",
       "\n",
       "                                     relevantTopicIds  \\\n",
       "58  [/m/02jjt, /m/02vxn, /m/02jjt, /m/02vxn, /m/0f...   \n",
       "68  [/m/02jjt, /m/0f2f9, /m/02jjt, /m/0f2f9, /m/0f...   \n",
       "\n",
       "                                          description  \\\n",
       "58  Arthur, D.W., and their family and friends pre...   \n",
       "68  5 talented Elf-testants are in the running for...   \n",
       "\n",
       "                                      topicCategories      videoId  \\\n",
       "58  [https://en.wikipedia.org/wiki/Film, https://e...  YBa8fm5w1WQ   \n",
       "68  [https://en.wikipedia.org/wiki/Entertainment, ...  1vHTAHEeTco   \n",
       "\n",
       "                   channelId  duration           publishedAt  \\\n",
       "58  UC6Qs46AHswdgMq08dqaQbQQ  PT54M35S  2015-11-02T14:10:57Z   \n",
       "68  UCJhhiv2zac33YdOC2He3uLg   PT43M5S  2019-12-14T05:00:01Z   \n",
       "\n",
       "                             title categoryId  madeForKids  \n",
       "58  Arthur&#39;s Perfect Christmas         30          1.0  \n",
       "68    Teamwork Makes the Tree Work         43          1.0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchDetails = dd.read_parquet('data/yt_info/details*')\n",
    "channelDetails = dd.read_parquet('data/yt_info/channel_details*')\n",
    "intersect = list(set(searchDetails.columns).intersection(channelDetails.columns))\n",
    "ddf = dd.concat([searchDetails[intersect], channelDetails[intersect]])\n",
    "ddf = ddf.drop_duplicates('videoId')\n",
    "exclude_channels = ['WYMT Television']\n",
    "ddf = ddf[~ddf.channelTitle.isin(exclude_channels)]\n",
    "\n",
    "just_for_kids = ddf[(ddf.madeForKids == 1) & (ddf.caption == 'true')].compute()\n",
    "subtitle_path = '/data/motes/yt_captions/{}/'.format(time.strftime('%m-%d'))\n",
    "\n",
    "problem_vids = []\n",
    "if os.path.exists('data/yt_caption_problems.txt'):\n",
    "    with open('data/yt_caption_problems.txt', mode='r') as f:\n",
    "        problem_vids = f.read().split('\\n')\n",
    "\n",
    "already_completed = [os.path.split(x)[1][:-5] for x in glob.glob('/data/motes/yt_captions/**/*') if x.endswith('.json')]\n",
    "already_completed += problem_vids\n",
    "print(len(just_for_kids), len(already_completed))\n",
    "just_for_kids = just_for_kids[~just_for_kids.videoId.isin(already_completed)]\n",
    "print(len(just_for_kids))\n",
    "just_for_kids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('captions_to_download.txt', mode='w') as f:\n",
    "    f.write(\"\\n\".join(just_for_kids.videoId.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err_vids = []\n",
    "for i, (ind, vid) in enumerate(just_for_kids.iterrows()):\n",
    "    print(i, vid.title)\n",
    "    try:\n",
    "        yt.fetch_and_save_transcript(vid.videoId, subtitle_path)\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except (youtube_transcript_api.TranscriptsDisabled,\n",
    "            youtube_transcript_api.NoTranscriptAvailable):\n",
    "        print('Err with {}'.format(vid.videoId))\n",
    "        err_vids.append(vid.videoId)\n",
    "        continue\n",
    "    except youtube_transcript_api.VideoUnavailable:\n",
    "        print('Probably rate limited')\n",
    "        break\n",
    "    time.sleep(np.random.randint(100, 1000)/100)\n",
    "\n",
    "#if len(err_vids):\n",
    "#    problem_vids += err_vids\n",
    "#    err_vids = []\n",
    "#with open('data/yt_caption_problems.txt', mode='w') as f:\n",
    "#    f.write(\"\\n\".join(problem_vids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Parse Dataset\n",
    "\n",
    "See [YTCaptionParsing.ipynb](YTCaptionParsing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
